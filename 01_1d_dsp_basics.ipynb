{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSP Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Wikipedia](https://en.wikipedia.org/wiki/Digital_signal_processing):\n",
    "> Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency.\n",
    "\n",
    "![](https://media.giphy.com/media/F0dcjkd0EH720/source.gif)\n",
    "\n",
    "When we get data from our sensors, we have to be aware that the signals we read will never ever be perfect. **Every sensor you use will have this issue**, and the processing of the readings you make will help you get the actual signal you are looking for.\n",
    "\n",
    "Today, we will go through different steps in the signal processing chain. Our targets for the day will be:\n",
    "\n",
    "1. **Get started with an all purpose language for many tasks: [Python](https://www.python.org/)**. Python is used for tasks that range from signal processing, machine learning, data analysis, web development, and many other things! We will see that starting with it is not difficult at all!\n",
    "2. **Understand the limitations of our systems** (no matter the cost or range)\n",
    "3. Have some tools to **clean signals and detect events**, and know when we might be doing something wrong\n",
    "4. Understand **how to log data and sample signals** and don't lose information\n",
    "5. Get some basics about **1-d and 2-d signal processing**, with the core libraries used for both cases and some inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "With this example we will get the first basics for DSP and start using some python packages. For this, we will load some data from a file, see what's inside and then plot it.\n",
    "\n",
    "Before we get started, some notes about the [Jupyter Notebook](http:/jupyter.org):\n",
    "- How to run a cell: Press SHIFT+Return\n",
    "- How to enter/exit cell edit mode: Enter/Escape\n",
    "- How to add a cell above: Esc + a\n",
    "- How to add a cell below: Esc + b\n",
    "- How to make a cell to me Markdown: Esc + m\n",
    "\n",
    "How to ask for help in **Jupyter Notebook**:\n",
    "\n",
    "- on an object, you can put help(object) and the documentation will be displayed\n",
    "- vars(object) to see the available functions\n",
    "- dir(object) to see the available properties\n",
    "- SHIFT + TAB (x2 or x3) to get interactive documentation on an object\n",
    "\n",
    "\n",
    "### Pandas\n",
    "\n",
    "One of the most important packages in python nowadays is called [pandas](https://pandas.pydata.org/). It's intended to provide efficient data structures and methods to handle large amounts of heterogeneous data, such as numbers, dates, strings...\n",
    "\n",
    "It's so important, that everyone imports it using the same name: **pd**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is really powerful and is the basic data framework of many of more complex data analysis and signal processing techniques. The most important items are the Series (1-d) and the DataFrame (2-d very powerful tabular data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help (pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of pandas functionality is built on top of [numpy](https://numpy.org/), a numerical calculation for python. Numpy is generally imported as np:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "\n",
    "Finally, matplotlib is a key package for making plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ice breaking example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/1d_data.csv')\n",
    "df.set_index('index', inplace = True);\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some of those metrics above manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df['y'].mean())\n",
    "print (df['y'].max())\n",
    "print (df['y'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Filtering is used when we want to reduce the amount of noise that a signal has. We call **noise** to the unwanted (and, in general, unknown) modifications that a signal may suffer during capture, storage, transmission, processing, or conversion. The process of removing the noise from a signal is called **filtering**.\n",
    "\n",
    "![](http://blog.catchpoint.com/wp-content/uploads/2016/06/Signal-processing.jpg)\n",
    "\n",
    "### Our new best friend: convolution\n",
    "\n",
    "Convolution is a DSP technique used in many fields, from 1-d signal analysis to more advanced image processing and video analysis in deep learning algorithms (CNN = Convolutional Neural Networks). It is very important to be familiar with it and how it works.\n",
    "\n",
    "From [DSP Guide](https://www.dspguide.com/ch6/4.htm):\n",
    "> Convolution is a formal mathematical operation, just as multiplication, addition, and integration. Addition takes two numbers and produces a third number, while convolution takes two signals and produces a third signal. Convolution is used in the mathematics of many fields, such as probability and statistics. In linear systems, convolution is used to describe the relationship between three signals of interest: the input signal, the impulse response, and the output signal.\n",
    "\n",
    "![](https://www.dspguide.com/graphics/F_6_8.gif)\n",
    "\n",
    "\n",
    "> Figure 6-8 illustrates (...) a flow diagram of how convolution occurs. Think of the input signal, x[n], and the output signal, y[n], as fixed on the page. The convolution machine, everything inside the dashed box, is free to move left and right as needed. The convolution machine is positioned so that its output is aligned with the output sample being calculated. Four samples from the input signal fall into the inputs of the convolution machine. These values are multiplied by the indicated samples in the impulse response, and the products are added. This produces the value for the output signal, which drops into its proper place. For example, y[n] is shown being calculated from the four input samples: x[3], x[4], x[5], and x[6].\n",
    "\n",
    "> To calculate y[7], the convolution machine moves one sample to the right. This results in another four samples entering the machine, x[4] through x[7], and the value for y[7] dropping into the proper place. This process is repeated for all points in the output signal needing to be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see later on, how we shape the function h[n] is very important, and can be used for many different purposes:\n",
    "- Filters\n",
    "- Inverters and attenuators\n",
    "- Calculate derivatives\n",
    "- Feature extraction\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One problem with convolution occurs when the convolution machine is located fully to the left or right of the input signal. \n",
    "In this position, it is trying to receive input from samples: x[-3], x[-2], x[-1] and x[0]. The problem is, three of these samples: x[-3], x[-2] and x[-1] do not exist! \n",
    "This same dilemma arises in (d), where the convolution machine tries to accept samples to the right of the defined input signal, points x[9], x[10] and x[11].\n",
    "\n",
    "> One way to handle this problem is by **inventing the nonexistent samples**. This involves adding samples to the ends of the input signal, with each of the added samples having a value of zero. This is called **padding** the signal with zeros. Instead of trying to access a nonexistent value, the convolution machine receives a sample that has a value of zero. Since this zero is eliminated during the multiplication, the result is mathematically the same as ignoring the nonexistent inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building our own convolution filter\n",
    "\n",
    "Let's then use our signal before and make some use of the convolution we have just learnt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formulas import smooth_convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(smooth_convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_smooth'] = smooth_convolution(df['y'], 21)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(df['y'].values))\n",
    "print (len(df['y_smooth'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y'].values\n",
    "print (f'Original signal length: {len(y)}')\n",
    "print (f'Smooth signal length: {len(df[\"y_smooth\"].values)}')\n",
    "\n",
    "half_window = 11\n",
    "print (f'Half window size: {half_window}')\n",
    "\n",
    "firstvals = y[0] - np.abs(y[1:half_window+1][::-1] - y[0])\n",
    "lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "nan_padding = []\n",
    "y_original = np.concatenate((firstvals*np.nan, list(map(float, y)), lastvals*np.nan))\n",
    "y_padding = np.concatenate((firstvals, list(map(float, y)), lastvals))\n",
    "y_smooth = np.concatenate((firstvals*np.nan, df['y_smooth'].values, lastvals*np.nan))\n",
    "print (f'Padded signal length: {len(y_padding)}, original signal + the size of the window (window = {2*half_window})')\n",
    "\n",
    "plt.plot(y_original, 'b.', label='original_signal')\n",
    "plt.plot(y_padding, 'r', label='padded_signal')\n",
    "plt.plot(y_smooth, 'g', label='smooth_signal')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_original, 'b.', label='original_signal')\n",
    "plt.plot(y_padding, 'r', label='padded_signal')\n",
    "plt.plot(y_smooth, 'g', label='smooth_signal')\n",
    "plt.xlim([100, 150])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add some components to our signal (note that the original amplitude is 2 (from -1 to 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_noisy_random'] = df['y'] + np.random.random(len(df['y'])) - 0.5\n",
    "df['y_noisy_sine'] = df['y'] + np.sin(np.arange(len(df['y'])))\n",
    "df.plot(y = 'y_noisy_random')\n",
    "df.plot(y = 'y_noisy_sine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['y_noisy_random'].values, label = 'noisy_random signal')\n",
    "plt.plot(smooth_convolution(df['y_noisy_random'], 21))\n",
    "plt.plot(smooth_convolution(df['y_noisy_random'], 7), label = 'noisy_random signal less filtered')\n",
    "plt.plot(smooth_convolution(df['y_noisy_random'], 21), label = 'noisy_sine signal more filtered')\n",
    "plt.plot(smooth_convolution(df['y_noisy_random'], 31), label = 'noisy_sine signal super filtered')\n",
    "plt.xlim([100, 200])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['y_noisy_sine'].values, label = 'noisy_sine signal')\n",
    "plt.plot(smooth_convolution(df['y_noisy_sine'], 7), label = 'noisy_sine signal less filtered')\n",
    "plt.plot(smooth_convolution(df['y_noisy_sine'], 21), label = 'noisy_sine signal more filtered')\n",
    "plt.plot(smooth_convolution(df['y_noisy_sine'], 31), label = 'noisy_sine signal super filtered')\n",
    "plt.xlim([100, 200])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential smoothing\n",
    "\n",
    "Exponential smoothing adds an exponential weighting function to our moving average filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formulas import exponential_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help (exponential_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_exp_0.2'] = exponential_smoothing(df['y'], 0.2)\n",
    "df['y_exp_0.1'] = exponential_smoothing(df['y'], 0.1)\n",
    "df['y_exp_0.05'] = exponential_smoothing(df['y'], 0.05)\n",
    "df.plot(y=['y', 'y_exp_0.2', 'y_exp_0.1', 'y_exp_0.05'])\n",
    "plt.xlim([100, 200])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_ns_exp_0.2'] = exponential_smoothing(df['y_noisy_sine'], 0.2)\n",
    "df['y_ns_exp_0.1'] = exponential_smoothing(df['y_noisy_sine'], 0.1)\n",
    "df['y_ns_exp_0.05'] = exponential_smoothing(df['y_noisy_sine'], 0.05)\n",
    "df.plot(y=['y_noisy_sine', 'y_ns_exp_0.2', 'y_ns_exp_0.1', 'y_ns_exp_0.05'])\n",
    "plt.xlim([100, 200])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats\n",
    "\n",
    "Important facts about filtering:\n",
    "- Not all the noise will be removed. The size of the window will determine how much you _clean_ the signal.\n",
    "- If you clean the signal too much, you loose amplitude in it and you loose your original signal\n",
    "- Some filters can introduce phasing (see below)\n",
    "- If you use convolution, you need to pad your signal, or trim it accordingly\n",
    "\n",
    "To cope with this problem, filters are many times applied forwards and backwards. Let's have a look at the scipy library.\n",
    "\n",
    "### Using libraries\n",
    "\n",
    "[Scipy](https://docs.scipy.org) is a general purpose scientific package in Python. Scipy signal package can be used for many of this signal processing tasks: https://docs.scipy.org/doc/scipy/reference/signal.html\n",
    "\n",
    "**scipy.filtfilt**\n",
    "\n",
    "Apply a digital filter **forward and backward** to a signal. This function applies a linear **digital filter twice**, once forward and once backwards. The combined filter has zero phase and a filter order twice that of the original. The function provides options for handling the edges of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "b, a = signal.butter(8, 0.125)\n",
    "b, a = signal.ellip(4, 0.01, 120, 0.125)  # Filter to be applied.\n",
    "\n",
    "for y_signal in ['y_noisy_sine', 'y_noisy_random']:\n",
    "    sig = df[y_signal].values \n",
    "    fgust = signal.filtfilt(b, a, sig, method=\"gust\")\n",
    "    fpad = signal.filtfilt(b, a, sig, padlen=50)\n",
    "    plt.plot(sig, 'k-', label=y_signal)\n",
    "    plt.plot(fgust, 'b-', linewidth=4, label=y_signal + '_gust')\n",
    "    plt.plot(fpad, 'c-', linewidth=1.5, label=y_signal + '_pad')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(y_signal)\n",
    "    plt.xlim([-100,100])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Detection\n",
    "\n",
    "The main idea behind detecting peaks is to make a sweep of our signal, looking for small areas that look like peaks. We can do so by multiplying our signal by a shifting \"peak\" ([wavelet](https://en.wikipedia.org/wiki/Wavelet) in formal terms) and see when the product of these two signals has a significant value. As we know, the product of two signals is called convolution, and we will use it again for finding peaks in our signals.\n",
    "\n",
    "### Easy example\n",
    "In this example, we will use a cwt to sweep our signal looking for peaks. We need to know roughly what our peaks will look like, so that we have a range for our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "xs = df.index\n",
    "peakind = signal.find_peaks_cwt(df['y'], np.arange(1,10))\n",
    "\n",
    "print (peakind)\n",
    "print (xs[peakind])\n",
    "plt.plot(df['y'].values)\n",
    "plt.plot(peakind, df.iloc[peakind, df.columns.get_loc(\"y\")], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have noise, thing get a bit trickier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "xs = df.index\n",
    "column = \"y_noisy_random\"\n",
    "peakind = signal.find_peaks_cwt(df[column], np.arange(15,20))\n",
    "\n",
    "plt.plot(df[column].values)\n",
    "plt.plot(peakind, df.iloc[peakind, df.columns.get_loc(column)], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 14\n",
    "half_window = (window_width)//2\n",
    "window = signal.general_gaussian(window_width, p=0.5, sig=20)\n",
    "# Padding\n",
    "firstvals = y[0] - np.abs(y[1:half_window][::-1] - y[0])\n",
    "lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "padded_signal = np.concatenate((firstvals, list(map(float, df[column])), lastvals))\n",
    "\n",
    "filtered = signal.fftconvolve(window, padded_signal, mode=\"valid\")\n",
    "filtered = (np.average(df[column]) / np.average(filtered)) * filtered\n",
    "print (df.shape)\n",
    "print (filtered.shape)\n",
    "df[column + '_filtered'] = filtered\n",
    "\n",
    "peakidx = signal.find_peaks_cwt(df[column + '_filtered'], np.arange(10,15), noise_perc=0.1)\n",
    "\n",
    "plt.plot(df[column].values)\n",
    "plt.plot(df[column + '_filtered'].values)\n",
    "plt.plot(peakind, df.iloc[peakind, df.columns.get_loc(column + '_filtered')], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 14\n",
    "half_window = (window_width)//2\n",
    "window = signal.general_gaussian(window_width, p=0.5, sig=20)\n",
    "# Without padding\n",
    "filtered = signal.fftconvolve(window, df[column], mode=\"full\")\n",
    "filtered = (np.average(df[column]) / np.average(filtered)) * filtered\n",
    "print (df.shape)\n",
    "print (filtered.shape)\n",
    "df[column + '_filtered'] = np.roll(filtered[:-window_width+1], -half_window)\n",
    "peakidx = signal.find_peaks_cwt(df[column + '_filtered'], np.arange(10,15), noise_perc=0.1)\n",
    "\n",
    "plt.plot(df[column].values)\n",
    "plt.plot(df[column + '_filtered'].values)\n",
    "plt.plot(peakind, df.iloc[peakind, df.columns.get_loc(column + '_filtered')], 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative\n",
    "\n",
    "To perform a derivative, we can use again our convolution friend, but in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def conv_derivative(y, box_pts):\n",
    "    '''\n",
    "        Calculate derivative of input signal using a convolutional filter\n",
    "        box_pts has to be even number\n",
    "    '''\n",
    "    \n",
    "    half_window = (box_pts-1) // 2\n",
    "\n",
    "    box = np.zeros(box_pts)\n",
    "    box[half_window+1:] = np.arange(half_window)+1\n",
    "    for index_box in range(half_window): box[index_box] = - box[-(index_box+1)]\n",
    "    print (box)\n",
    "    box = - box/((math.sqrt(half_window-1))*(half_window-1))\n",
    "    # Using svagol filter coefficients we need to compensate for window size. \n",
    "    # This is just an approximation and won't work with window > 10\n",
    "    \n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, list(map(float, y)), lastvals))\n",
    "    y_derivative = np.convolve(y, box, mode='valid')\n",
    "    return y_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_plot = ['y']\n",
    "for derivative_number in [5, 7]:\n",
    "    df[f'y_derivative_{derivative_number}'] = conv_derivative(df['y'], derivative_number)\n",
    "    list_plot.append(f'y_derivative_{derivative_number}')\n",
    "df.plot(y = list_plot)\n",
    "plt.xlim([20, 100])\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General guidelines\n",
    "\n",
    "- Always try to remove the noise from the signal before doing anything else in it\n",
    "- Be careful with numerical problems - small numbers are not handled well numerically\n",
    "- Use filters with caution, try different options before going for a final selection of parameters\n",
    "- There is no general set of parameters for everything\n",
    "- Do not try to find a solution that suits you, but that suits your problem. Quick solutions are often not extrapolated out of laboratory conditions\n",
    "\n",
    "## References and more resources\n",
    "\n",
    "### Python intro\n",
    "- Python beginner's guide: https://wiki.python.org/moin/BeginnersGuide\n",
    "- Conda documentation: https://docs.conda.io/projects/conda/en/latest/index.html\n",
    "- Install an environment from an environment yml file: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file\n",
    "\n",
    "### DSP Specifics\n",
    "- Notes on Convolution from DSP Guide: \"The Scientist and Engineer's Guide to Digital Signal Processing, copyright Â©1997-1998 by Steven W. Smith. For more information visit the book's website at: www.DSPguide.com\"\n",
    "- [Noise and sampling](https://en.wikipedia.org/wiki/Noise_(signal_processing))\n",
    "- [Scipy Package](https://docs.scipy.org/doc/scipy/reference/)\n",
    "- [Pandas package](https://pandas.pydata.org/)\n",
    "- [Numpy](https://numpy.org/)\n",
    "- [Scipy Lectures](https://scipy-lectures.org/)\n",
    "- [Scikits](https://scikits.appspot.com/scikits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
