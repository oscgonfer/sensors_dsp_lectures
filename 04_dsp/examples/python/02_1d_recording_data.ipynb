{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording data in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will look at how we can stream data from our sensors in real time. We will learn how to store that data in a csv file and how to process it using our functions and pandas. Let's load some stuff first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.serialdevice import *\n",
    "from src.formulas import*\n",
    "from threading import Thread\n",
    "import itertools  \n",
    "import os\n",
    "# Bokeh plotting tools\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from bokeh.models import Panel, Tabs\n",
    "from bokeh.layouts import column, gridplot\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data\n",
    "We can directly export data using std_out redirection towards anything. For instance, if we use platformio or screen, we could do something like:\n",
    "\n",
    "```\n",
    "pio device monitor -b 115200 > output.txt\n",
    "```\n",
    "\n",
    "The ```>``` is redirecting the output of the ```pio device monitor``` command towards a text file, which is basically a log of the sensor. However, we can do better, and use the power of pandas to do some extra calculations and add a timestamp to the data we receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dS = pd.Series(np.arange(0,100,0.1))\n",
    "# dS;\n",
    "dS.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dS.to_csv('data/dummy_series.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the sensors\n",
    "\n",
    "To log the data coming from the sensors, we will use a serial interface with the [pySerial](https://github.com/pyserial/pyserial) package. \n",
    "\n",
    "Other ways to interface with sensors and more scientific instrumentation options can be found in the [pyMeasure](https://github.com/ralph-group/pymeasure) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import serial.tools.list_ports\n",
    "\n",
    "devices = list(serial.tools.list_ports.comports())\n",
    "for d in devices: print(str(devices.index(d) + 1) + ' --- ' + d.device + ' --- ' + str(d.description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three important frequencies to take into account:\n",
    "- The frequency at which the sensor gives us data\n",
    "- The frequency at which we sample the sensor\n",
    "- The natural frequencies that we want to capture\n",
    "\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:Signal_Sampling.png#/media/File:Signal_Sampling.png\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/50/Signal_Sampling.png\" width=\"600px\" alt=\"Signal Sampling.png\"></a><br>By <a href=\"//commons.wikimedia.org/wiki/User:Email4mobile\" title=\"User:Email4mobile\">Email4mobile</a> (<a href=\"//commons.wikimedia.org/wiki/User_talk:Email4mobile\" title=\"User talk:Email4mobile\">talk</a>) - <a class=\"external free\" href=\"https://en.wikipedia.org/wiki/File:Signal_Sampling.png\">http://en.wikipedia.org/wiki/File:Signal_Sampling.png</a>, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=8693098\">Link</a></p>\n",
    "\n",
    "**Key take aways:**\n",
    "\n",
    "1. We don't need to sample faster than the sensor gives us data\n",
    "2. We need to sample at least twice as fast as the Nyquist frequency ([Nyquist-Shannon theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp = serialdevice()\n",
    "if esp.set_serial(): esp.update_serial()\n",
    "print (f'Device serial number: {esp.serialNumber}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-explanatory\n",
    "store_to_csv = True\n",
    "# Frequency at which we will record the sensor data\n",
    "raster = 0.05\n",
    "# Default to 5 - increase if you need more smoothing\n",
    "buffer_length = 5\n",
    "# Number of points to show on the plot\n",
    "n_show = 500\n",
    "\n",
    "''' \n",
    "Set channels to monitor and calculate \n",
    "\n",
    "Each channel can have several processes to be done, in a sequential order, i.e.:\n",
    "'y': {...\n",
    "     '8': {'clean_na': ['drop', 'other']}, ...\n",
    "The dict passes the name of the function, one parameter to it and if we want it:\n",
    "- inplace: replace the channel with the formula, on the same column (inplace implies same + replacement)\n",
    "- same: plot it on the same plot as the original channel\n",
    "- other: plot it on another plot\n",
    "''' \n",
    "\n",
    "channels_to_monitor = {'y': {'1': {'clean_na': ['fill', 'inplace']},\n",
    "                             '2': {'smooth_convolution': [3, 'same', 'inplace']},\n",
    "                             '3': {'exponential_smoothing': [0.2, 'same']},\n",
    "                             '4': {'exponential_smoothing': [0.1, 'same']},\n",
    "                             '5': {'exponential_smoothing': [0.05, 'same']},\n",
    "                             '6': {'exponential_smoothing': [0.03, 'same']},\n",
    "                             '7': {'exponential_smoothing': [0.02, 'same']},\n",
    "                             '8': {'exponential_smoothing': [0.01, 'same']},#,\n",
    "                             # '9': {'time_derivative': [1, 'same']},\n",
    "                             # '10': {'time_diff': [1, 'other']}\n",
    "                            }}\n",
    "\n",
    "if store_to_csv: path_to_store = os.path.join(os.getcwd(), 'data/csv_export.csv'); print (f'Saving stream to: {path_to_store}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a separate [thread](https://docs.python.org/2/library/threading.html) for recording the data and processing it. This thread will also be in charge of streaming the data to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "    for channel in channels_to_monitor.keys():\n",
    "        for process_number in channels_to_monitor[channel].keys():\n",
    "            # Process and formula\n",
    "            process = list(channels_to_monitor[channel][process_number])[0]\n",
    "            formula = process + f\"(data['{channel}'], channels_to_monitor['{channel}']['{process_number}']['{process}'][0])\" \n",
    "            # Name for new channel depending on inplace or not\n",
    "            if 'inplace' in channels_to_monitor[channel][process_number][process]: channel_new_name = channel\n",
    "            else: channel_new_name = channel + '_' + process + '_' + str(channels_to_monitor[channel][process_number][process][0])\n",
    "            # Calculate\n",
    "            if data.empty: data[channel_new_name] = []\n",
    "            else: data[channel_new_name] = eval(formula)\n",
    "    return data\n",
    "\n",
    "# Start the stream\n",
    "esp.start_streaming(buffer_length = buffer_length, raster = raster)\n",
    "# Create plot columnar data\n",
    "plot_data = ColumnDataSource(data = process_data(esp.worker.example))\n",
    "# Number of tabs\n",
    "n_tabs = len(list(channels_to_monitor.keys()))\n",
    "tabs = Tabs(tabs = [])\n",
    "colors = itertools.cycle(palette)\n",
    "\n",
    "for channel in channels_to_monitor.keys():\n",
    "    gridplots = list()\n",
    "    p = figure(background_fill_color=\"#fafafa\", x_axis_type='datetime')\n",
    "    gridplots.append([p])\n",
    "    p.line(y = channel, x=\"index\", source = plot_data, legend_label = channel)\n",
    "    p.title.text = f'Streaming {channel}'\n",
    "    p.yaxis.axis_label = f'{channel}'\n",
    "    p.xaxis.axis_label = 'Timestamp'\n",
    "\n",
    "    for process_number in channels_to_monitor[channel].keys():\n",
    "        process = list(channels_to_monitor[channel][process_number])[0]\n",
    "        # We have already plotted it if it was inplace\n",
    "        if 'inplace' in channels_to_monitor[channel][process_number][process]: continue\n",
    "\n",
    "        channel_name = channel + '_' + process + '_' + str(channels_to_monitor[channel][process_number][process][0])\n",
    "        if 'same' in channels_to_monitor[channel][process_number][process]:\n",
    "            p.line(y=channel_name, x=\"index\", legend_label = channel_name, source = plot_data, color = next(colors))\n",
    "        elif 'other' in channels_to_monitor[channel][process_number][process]:\n",
    "            p = figure(background_fill_color=\"#fafafa\", x_axis_type='datetime')\n",
    "            p.line(y=channel_name, x=\"index\", legend_label = channel_name, source = plot_data, color = next(colors))\n",
    "            p.yaxis.axis_label = f'{channel_name}'\n",
    "            p.xaxis.axis_label = 'Timestamp'\n",
    "            gridplots.append([p])\n",
    "\n",
    "    p.legend.location='top_left'\n",
    "    p.legend.click_policy=\"hide\"\n",
    "\n",
    "    grid = gridplot(gridplots,  plot_width=1000, plot_height=500)\n",
    "    tab = Panel(child=grid, title=channel)\n",
    "    tabs.tabs.append(tab)\n",
    "\n",
    "handle = show(tabs, notebook_handle=True)\n",
    "stop_threads = False\n",
    "\n",
    "def worker_call(id, device, stop):\n",
    "    df_data = pd.DataFrame()\n",
    "    \n",
    "    while True:\n",
    "        if not device.worker.output.empty():\n",
    "            new_data = device.worker.output.get()\n",
    "            if 'Time' in new_data.columns: new_data.rename(columns={'Time': 'index'}, inplace=True)\n",
    "            new_data = new_data.set_index('index')\n",
    "\n",
    "            if df_data.empty: df_data = new_data\n",
    "            else: df_data = pd.concat([df_data, new_data], sort = False)\n",
    "            \n",
    "            # We process everything\n",
    "            # processed_data = process_data(new_data)    \n",
    "            # if df_data.empty: df_data = processed_data\n",
    "            #else: df_data = pd.concat([df_data, processed_data], sort = False)\n",
    "            \n",
    "            # We only process what we show\n",
    "            processed_data = process_data(df_data.tail(n_show))\n",
    "            # Stream and processing\n",
    "            plot_data.stream(processed_data, n_show)\n",
    "            \n",
    "            # Store to csv\n",
    "            if store_to_csv: df_data.to_csv(path_to_store, sep = \",\")\n",
    "            \n",
    "            # Update plot\n",
    "            push_notebook(handle = handle)\n",
    "\n",
    "            if stop(): print(\"Finished thread\"); break\n",
    "\n",
    "thread = Thread(target=worker_call, args=(id, esp, lambda: stop_threads))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_threads = True\n",
    "if esp.worker.is_alive():\n",
    "    print ('Terminating device worker')\n",
    "    esp.worker.terminate()\n",
    "    esp.worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and more examples\n",
    "\n",
    "- [Sampling](https://en.wikipedia.org/wiki/Sampling_(signal_processing))\n",
    "- [PySerial](https://pyserial.readthedocs.io/en/latest/index.html)\n",
    "- [Bokeh Streaming](https://docs.bokeh.org/en/latest/docs/user_guide/data.html?highlight=streaming%20data)\n",
    "- [PyLab](https://scipy.github.io/old-wiki/pages/PyLab)\n",
    "- Other packages for streaming data: https://streamz.readthedocs.io/en/latest/index.html\n",
    "- [Create applications for DAQs using python](https://www.dashdaq.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
