{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Introduction to image processing\n",
    "\n",
    "In this part of the workshop, we will talk about how to deal with 2-d data: mainly images, and then go through some introduction to CNNs.\n",
    "\n",
    "## How a computer sees an image\n",
    "\n",
    "As we know, images are comprised of a set of pixels that represent colors. One of the most common ways to represent an image is with an RGB matrix:\n",
    "\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:Beyoglu_4671_tricolor.png#/media/File:Beyoglu_4671_tricolor.png\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/3/33/Beyoglu_4671_tricolor.png\" alt=\"Beyoglu 4671 tricolor.png\" width=\"1640\" height=\"1080\"></a><br>By Â© Nevit Dilmen, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=18673639\">Link</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express this in the shape of grayscale matrix for each of the channels:\n",
    "![](https://brohrer.github.io/images/image_processing/three_d_array.png)\n",
    "\n",
    "By: https://brohrer.github.io/convert_rgb_to_grayscale.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def np_from_img(fname):\n",
    "    return np.asarray(Image.open(fname), dtype=np.float32)\n",
    "\n",
    "def save_as_img(ar, fname):\n",
    "    Image.fromarray(ar.round().astype(np.uint8)).save(fname)\n",
    "\n",
    "def norm(ar):\n",
    "    return 255.*np.absolute(ar)/np.max(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'img/tree.jpeg'\n",
    "img = np_from_img(file_name)\n",
    "img_norm = norm(Image.fromarray(img.round().astype(np.uint8)))\n",
    "# print (img.shape)\n",
    "# print (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.round().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting edges in images\n",
    "\n",
    "We will use a sobel-filter with our beloved convolution to detect the edgest of our image. First, let's have a look at the shape of our image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.learnopencv.com/wp-content/uploads/2017/11/convolution-example-matrix.gif)\n",
    "\n",
    "From https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(signal.convolve(img_norm[:,:,0], [[1.],[0],[-1.]]).round().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from http://juanreyero.com/article/python/python-convolution.html\n",
    "def common_size(a1, a2):\n",
    "    \"\"\"Chop-off the first rows and cols from the two numpy arrays a1\n",
    "    and a2 so that they end up having the same size.\n",
    "    >>> print common_size(np.array([[0, 0],\n",
    "    ...                             [1, 2],\n",
    "    ...                             [3, 4]]),\n",
    "    ...                   np.array([[0, 5, 6],\n",
    "    ...                             [0, 7, 8]]))\n",
    "    (array([[1, 2],\n",
    "           [3, 4]]), array([[5, 6],\n",
    "           [7, 8]]))\n",
    "    \"\"\"\n",
    "    (r1, c1) = a1.shape\n",
    "    (r2, c2) = a2.shape\n",
    "    return (a1[r1-r2 if r1>r2 else 0:,\n",
    "               c1-c2 if c1>c2 else 0:],\n",
    "            a2[r2-r1 if r2>r1 else 0::,\n",
    "               c2-c1 if c2>c1 else 0:])\n",
    "\n",
    "def gradient(im):\n",
    "    imv, imh = common_size(signal.convolve(im, [[1., -1.]]),\n",
    "                           signal.convolve(im, [[1.], [-1.]]))\n",
    "    return np.sqrt(np.power(imv, 2)+np.power(imh, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(gradient(img_norm[:,:,2]).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Using libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "\n",
    "# Create an image object\n",
    "image = Image.open(\"img/tree.jpeg\")\n",
    "# Find the edges by applying the filter ImageFilter.FIND_EDGES\n",
    "imageWithEdges = image.filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "# Original image\n",
    "image.show()\n",
    "# Display the new image with edge detection done\n",
    "imageWithEdges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature detection\n",
    "\n",
    "### Theory of using CNNs\n",
    "\n",
    "![](https://adeshpande3.github.io/assets/Cover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and more examples\n",
    "\n",
    "- [OpenCV - Open Source Computer Vision Library](https://opencv.org/)\n",
    "- [OpenCV Python](https://pypi.org/project/opencv-python/)\n",
    "- [OpenCV Github](https://github.com/opencv/opencv/)\n",
    "- [Open Model Zoo repository](https://github.com/opencv/open_model_zoo/)\n",
    "- [OpenVino](https://github.com/intel/ros2_openvino_toolkit)\n",
    "- [OpenFrameworks - Creative coding in C++- good framework for using Kinect and depth cameras](https://openframeworks.cc/)\n",
    "- [ofx github search - Contributed frameworks for openframeworks](https://github.com/search?utf8=%E2%9C%93&q=ofx)\n",
    "- [Processing - Creative coding in Java](https://processing.org/)\n",
    "- [P5 - Creative coding in Javascripts](https://p5js.org/)\n",
    "\n",
    "### Image processing\n",
    "\n",
    "- [Image magick](https://imagemagick.org/index.php)\n",
    "- [Keras tutorial for CNN](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "- [Understanding CNNs - Part 1, 2 and 3](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "\n",
    "### Video processing\n",
    "\n",
    "- [FFMPEG](https://ffmpeg.org/)\n",
    "- [ffmpeg-python: Python Bindings for ffmpeg](https://github.com/kkroening/ffmpeg-python)\n",
    "- [YOLO - Object detection in video](https://pjreddie.com/)\n",
    "- [Yolo V3 paper](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n",
    "- https://github.com/intel/ros2_openvino_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
